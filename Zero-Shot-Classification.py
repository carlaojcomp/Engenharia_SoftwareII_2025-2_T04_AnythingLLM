from sentence_transformers import SentenceTransformer
import torch
from typing import List, Dict, Any
from torch.nn.functional import cosine_similarity

# ===============================================================
# üîπ Dicion√°rio de arquiteturas com descri√ß√µes detalhadas
# ===============================================================
ARCHITECTURE_DESCRIPTIONS = {
    "MVC": (
        "Model-View-Controller (MVC) √© um padr√£o arquitetural que separa "
        "a aplica√ß√£o em tr√™s camadas: Model (l√≥gica de dados e regras de neg√≥cio), "
        "View (interface com o usu√°rio) e Controller (coordena a intera√ß√£o entre "
        "modelos e vis√µes). √â muito usado em frameworks web como Django, Rails e Spring MVC."
    ),
    "Microservices": (
        "Arquitetura de Microservices divide a aplica√ß√£o em servi√ßos pequenos, "
        "independentes e implant√°veis separadamente. Cada servi√ßo √© respons√°vel por uma "
        "fun√ß√£o espec√≠fica e se comunica com outros via APIs. Facilita escalabilidade, "
        "resili√™ncia e implanta√ß√£o cont√≠nua."
    ),
    "Layered architecture": (
        "A arquitetura em camadas organiza o sistema em n√≠veis de abstra√ß√£o distintos, "
        "como apresenta√ß√£o, l√≥gica de neg√≥cio e acesso a dados. Cada camada depende apenas "
        "da camada imediatamente inferior. √â um modelo cl√°ssico de sistemas corporativos."
    ),
    "Monolithic": (
        "Arquitetura monol√≠tica √© aquela em que toda a l√≥gica de aplica√ß√£o est√° agrupada "
        "num √∫nico bloco implant√°vel. √â mais simples de desenvolver inicialmente, mas "
        "dificulta a escalabilidade e manuten√ß√£o em sistemas grandes."
    ),
    "Event-driven architecture": (
        "Arquitetura orientada a eventos √© baseada na emiss√£o, detec√ß√£o e rea√ß√£o a eventos. "
        "Os componentes s√£o fracamente acoplados e se comunicam de forma ass√≠ncrona via filas "
        "ou brokers como Kafka e RabbitMQ. Ideal para sistemas altamente reativos e escal√°veis."
    ),
    "Plugin/modular architecture": (
        "Arquitetura modular ou de plugins permite estender funcionalidades do sistema "
        "sem alterar seu n√∫cleo. Cada m√≥dulo ou plugin pode ser adicionado ou removido "
        "de forma independente. Usada em IDEs, jogos e plataformas extens√≠veis."
    ),
    "Serverless": (
        "Arquitetura Serverless executa fun√ß√µes sob demanda na nuvem, sem que o desenvolvedor "
        "precise gerenciar servidores. Cada fun√ß√£o √© acionada por eventos e escala automaticamente. "
        "Usada em plataformas como AWS Lambda e Google Cloud Functions."
    ),
    "CQRS": (
        "Command Query Responsibility Segregation (CQRS) separa opera√ß√µes de escrita (commands) "
        "e leitura (queries) em modelos distintos, otimizando desempenho e consist√™ncia. "
        "√â comum em sistemas com alta carga de leitura e necessidade de eventos consistentes."
    ),
    "Hexagonal architecture": (
        "Arquitetura Hexagonal (ou Ports and Adapters) separa o n√∫cleo da aplica√ß√£o "
        "das interfaces externas (banco de dados, UI, APIs) por meio de portas e adaptadores. "
        "Facilita testes e independ√™ncia de infraestrutura."
    ),
    "Onion architecture": (
        "Arquitetura Onion √© uma varia√ß√£o da Hexagonal, com camadas conc√™ntricas "
        "em torno do dom√≠nio central. Cada camada depende apenas da camada mais interna. "
        "Promove alta coes√£o e baixo acoplamento."
    ),
    "Client-server": (
        "Arquitetura cliente-servidor separa o sistema em dois pap√©is principais: "
        "o cliente (interface que solicita recursos) e o servidor (componente que os fornece). "
        "Modelo cl√°ssico da web moderna."
    ),
    "Service-oriented architecture": (
        "Arquitetura orientada a servi√ßos (SOA) organiza o sistema como um conjunto de servi√ßos "
        "reutiliz√°veis e interoper√°veis que se comunicam por protocolos padronizados, "
        "como SOAP e REST. √â um precursor dos microservi√ßos."
    ),
}

# ===============================================================
# üîπ Fun√ß√µes utilit√°rias
# ===============================================================
def load_embedding_model(model_name: str = "all-MiniLM-L6-v2"):
    """Carrega modelo de embedding Sentence-Transformers."""
    # Carrega o modelo de forma otimizada
    model = SentenceTransformer(model_name)
    # Retornamos o modelo. O tokenizer est√° embutido nele
    return model

# NOVO M√âTODO DE EMBEDDING
def get_embedding(text: str, model) -> torch.Tensor:
    """Retorna embedding da senten√ßa usando o m√©todo otimizado do S-T."""
    embedding_list = model.encode([text], convert_to_tensor=True, show_progress_bar=False)
    return embedding_list[0] # Retorna o tensor do primeiro (e √∫nico) item da lista

# Ajuste o 'compute_semantic_similarity' para usar o novo 'load_embedding_model'
def compute_semantic_similarity(description: str,
                            architecture_descriptions: Dict[str, str] = ARCHITECTURE_DESCRIPTIONS,
                            model_name: str = "all-MiniLM-L6-v2") -> Dict[str, Any]:
    """Calcula similaridade entre a descri√ß√£o do sistema e embeddings das arquiteturas."""

    # O S-T agora retorna apenas o modelo, n√£o o tokenizer separadamente
    model = load_embedding_model(model_name)

    # Passe apenas o modelo para get_embedding
    desc_emb = get_embedding(description, model)

    results = []
    for label, desc in architecture_descriptions.items():
        label_emb = get_embedding(desc, model)
        sim = cosine_similarity(desc_emb.unsqueeze(0), label_emb.unsqueeze(0)).item()
        results.append((label, sim))

    results = sorted(results, key=lambda x: x[1], reverse=True)

    return {
        "sequence": description,
        "labels_scores": results
    }

def pretty_print(result: Dict[str, Any], top_k: int = 5):
    print("Texto analisado:\n", result["sequence"][:800], "...\n")
    print(f"Top {top_k} arquiteturas mais semelhantes (label : similaridade):")
    for label, score in result["labels_scores"][:top_k]:
        print(f"  - {label:<30} : {score:.4f}")

# ===============================================================
# üîπ Execu√ß√£o principal
# ===============================================================
if __name__ == "__main__":
    description = """
    Linguagem dominante √© o JS.
    Frontend: ViteJs + React.
    Backend: NodeJs + Express (JS).
    Permite rodar localmente (Desktop) e em servidores (Docker).
    Funcionalidade principal: RAG (Gera√ß√£o Aumentada por Recupera√ß√£o).
    Objetivo: construtor no-code de IAs.
    Suporta m√∫ltiplos modelos LLM (Gemini, OpenAI, Ollama, etc.).
    Permite escolher Vector DB (LanceDB, PGVector, Pinecone, etc.).
    Backend dividido em dois servi√ßos NodeJS/Express:
      - Server: gerencia intera√ß√µes com DB.
      - Collector: coleta e processa documentos enviados.
    """

    result = compute_semantic_similarity(description)
    pretty_print(result, top_k=10)
